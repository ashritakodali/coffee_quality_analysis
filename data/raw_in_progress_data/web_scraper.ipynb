{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2e1dfbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install selenium\n",
    "# pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41756076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import time\n",
    "import dotenv\n",
    "import os\n",
    "import lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8518704d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in username and password using a .env file\n",
    "dotenv.load_dotenv()\n",
    "login_email = os.getenv('cqi_username')\n",
    "login_password = os.getenv('cqi_password')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b412818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROBUSTA COFFEE BEANS\n",
    "\n",
    "# it should open each link one by one and get the data and make 5 files\n",
    "# if it takes to long, selenium will not be able to parse it and will have an incomplete file (this is okay,\n",
    "# it just won't be included in the final dataset)\n",
    "\n",
    "# should run in one go\n",
    "\n",
    "# open chromedriver\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "time.sleep(2)\n",
    "\n",
    "# navigate to login page\n",
    "driver.get('https://database.coffeeinstitute.org/login')\n",
    "time.sleep(3)\n",
    "\n",
    "# submit login credentials\n",
    "form = wait.until(EC.presence_of_element_located((By.XPATH, '//html/body/content[@class=\"scrollable\"]/div[@class=\"container page\"]/div[@class=\"form short\"]/div[@class=\"login panel\"]/form'))) # NOTE: find_element_by_* has been removed\n",
    "\n",
    "# form = driver.find_element('xpath', '//html/body/content[@class=\"scrollable\"]/div[@class=\"container page\"]/div[@class=\"form short\"]/div[@class=\"login panel\"]/form') # NOTE: find_element_by_* has been removed\n",
    "username = driver.find_element('name', \"username\")\n",
    "password = driver.find_element('name', \"password\")\n",
    "time.sleep(2)\n",
    "\n",
    "username.send_keys(login_email)\n",
    "password.send_keys(login_password)\n",
    "driver.find_element('class name', \"submit\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# navigate to coffees page, then to arabicas page containing links to all quality reports\n",
    "# coffees = driver.find_element('xpath', '//html/body/header/nav[@id=\"main\"]/div[@class=\"container\"]/div[@class=\"in\"]/a[@href=\"/coffees\"]').click()\n",
    "coffees = wait.until(EC.presence_of_element_located((By.XPATH, '//html/body/header/nav[@id=\"main\"]/div[@class=\"container\"]/div[@class=\"in\"]/a[@href=\"/coffees\"]'))).click()#\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element('link text', 'Robusta Coffees').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# these values can be changed if this breaks midway through collecting data to pick up close to where you left off\n",
    "page = 0\n",
    "coffeenum = 0\n",
    "\n",
    "while True:\n",
    "\tprint('page {}'.format(page))\n",
    "\n",
    "\t# 50 rows in these tables * 7 columns per row = 350 cells. Every 7th cell clicks through to that coffee's data page\n",
    "\tfor i in range(1, 400, 8):\n",
    "\t\ttime.sleep(2)\n",
    "\n",
    "\t\t# paginate back to the desired page number\n",
    "\t\t# don't think there's a way around this - the back() option goes too far back\n",
    "\t\t# some page numbers aren't available in the ui, but 'next' always is unless you've reached the end\n",
    "\t\tfor p_num in range(page):\n",
    "\t\t\tpage_buttons = driver.find_elements('class name', 'paginate_button')\n",
    "\t\t\tpage_buttons[-1].click() # the 'next' button\n",
    "\t\t\ttime.sleep(1)\n",
    "\t\t\tpage_buttons = driver.find_elements('class name', 'paginate_button')\n",
    "\n",
    "\t\t# select the cell to click through to the next coffee-data page\n",
    "\t\ttime.sleep(2) # this next line errors out sometimes, maybe it needs more of a time buffer\n",
    "\t\ttest_page = driver.find_elements('xpath', '//td')[i].click()\n",
    "\t\ttime.sleep(2)\n",
    "\t\tprint('rows: ')\n",
    "\t\tprint(len(driver.find_elements('xpath', \"//tr\")))\n",
    "\t\ttables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "\t\t# loop over all coffee reports on the page, processing each one and writing to csv\n",
    "\t\tprint('tables: ')\n",
    "\t\tprint(len(tables))\n",
    "\t\tj = 0\n",
    "\t\tfor tab in tables:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tt = BeautifulSoup(tab.get_attribute('outerHTML'), \"html.parser\")\n",
    "\t\t\t\t#print(t)\n",
    "\t\t\t\tdf = pd.read_html(str(t))\n",
    "\t\t\t\tname = 'coffee_{}_table_{}.csv'.format(coffeenum, j)\n",
    "\t\t\t\tdf[0].to_csv(name)\n",
    "\t\t\t\tprint(name)\n",
    "\t\t\texcept:\n",
    "\t\t\t\t# only one's needed but I want this to be obnoxious since it's the only way I'm logging this currently\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\tj += 1\n",
    "\n",
    "\t\t# go back to page with all other coffee results\n",
    "\t\t#driver.back() # note: this isn't working as expected, manually going back to pg 1 via url instead\n",
    "\t\tdriver.get('https://database.coffeeinstitute.org/coffees/robusta')\n",
    "\t\ttime.sleep(2)\n",
    "\t\tcoffeenum += 1\n",
    "\n",
    "\tpage += 1\n",
    "\tif page == 2:\n",
    "\t\tbreak\n",
    "\n",
    "\n",
    "# close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f1f651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Change this to your working directory\n",
    "folder_path = '/Users/ashik/UVA/ds 6021 project/robusta_final'  # or arabica\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# List all files in directory\n",
    "all_files = os.listdir()\n",
    "\n",
    "# Keep only valid files matching coffee_#_table_#.csv\n",
    "coffee_list = (\n",
    "    pd.DataFrame({'files': all_files})\n",
    "    .query(\"files.str.match(r'^coffee_\\\\d+_table_\\\\d+\\\\.csv$')\", engine='python')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Check how many valid coffee files were found\n",
    "print(f\"Found {len(coffee_list)} valid coffee files.\")\n",
    "if len(coffee_list) == 0:\n",
    "    raise ValueError(\"No valid coffee_#_table_#.csv files found. Check your folder path.\")\n",
    "\n",
    "# Split filenames to identify coffee IDs and tables\n",
    "coffee_list_split_temp = coffee_list['files'].str.split(pat='_', n=2, expand=True)\n",
    "coffee_list_split_temp.columns = ['coffee', 'id', 'tables']\n",
    "\n",
    "# Combine parts for easier grouping\n",
    "coffee_list_split = pd.DataFrame({\n",
    "    'coffee': coffee_list_split_temp['coffee'] + '_' + coffee_list_split_temp['id'],\n",
    "    'tables': coffee_list_split_temp['tables']\n",
    "})\n",
    "\n",
    "# Count tables per coffee\n",
    "table_counts = coffee_list_split.groupby('coffee').count()\n",
    "print(\"Coffees missing some tables:\")\n",
    "print(table_counts[table_counts['tables'] != 5])\n",
    "\n",
    "# Identify which coffee IDs to skip\n",
    "incomplete = table_counts[table_counts['tables'] != 5].index.tolist()\n",
    "skips = [int(c.split('_')[1]) for c in incomplete]\n",
    "print(\"Skipping:\", skips)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i in range(210):\n",
    "    if i in skips:\n",
    "        print(f\"Skipping {i}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df0 = pd.read_csv(f'coffee_{i}_table_0.csv')\n",
    "        df1 = pd.read_csv(f'coffee_{i}_table_1.csv')\n",
    "        df2 = pd.read_csv(f'coffee_{i}_table_2.csv')\n",
    "        df3 = pd.read_csv(f'coffee_{i}_table_3.csv')\n",
    "        df4 = pd.read_csv(f'coffee_{i}_table_4.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing file(s) for coffee_{i}\")\n",
    "        continue\n",
    "\n",
    "    # Process df1\n",
    "    df1.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df1['one'].tolist()\n",
    "    colnames2 = df1['three'].tolist()\n",
    "    data1 = df1['two'].tolist()\n",
    "    data2 = df1['four'].tolist()\n",
    "    df1_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df2\n",
    "    df2.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df2['one'].tolist()\n",
    "    colnames2 = df2['three'].tolist()\n",
    "    data1 = df2['two'].tolist()\n",
    "    data2 = df2['four'].tolist()\n",
    "    df2_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df3\n",
    "    df3.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df3['one'].tolist()\n",
    "    colnames2 = df3['three'].tolist()\n",
    "    data1 = df3['two'].tolist()\n",
    "    data2 = df3['four'].tolist()\n",
    "    df3_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df4\n",
    "    df4.columns = ['zero', 'one', 'two']\n",
    "    colnames1 = df4['one'].tolist()\n",
    "    data1 = df4['two'].tolist()\n",
    "    df4_processed = pd.DataFrame([data1], columns=colnames1)\n",
    "\n",
    "    if i > 1:\n",
    "        prev_cols = df.columns\n",
    "\n",
    "    df = pd.concat([df1_processed, df2_processed, df3_processed, df4_processed], axis=1)\n",
    "    df = df.rename(columns={np.nan: \"NA\"})\n",
    "    df_list.append(df)\n",
    "    print(i)\n",
    "\n",
    "    these_cols = df.columns\n",
    "    if i > 1:\n",
    "        pass\n",
    "\n",
    "j = 0\n",
    "for i in df_list:\n",
    "    print(f\"{j} shape: {i.shape}\")\n",
    "    j += 1\n",
    "\n",
    "df_final = pd.concat(df_list, axis=0)\n",
    "print(df_final.columns)\n",
    "print(df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "df_final.to_csv('df_1_robusta.csv', index=False)\n",
    "\n",
    "# figure out what coffee_89 is and have to manually to add it back\n",
    "# https://database.coffeeinstitute.org/coffee/991448 is missing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d16b474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARABICA COFFEE BEANS\n",
    "\n",
    "## this one will time out because of issues with selenium and memory space?\n",
    "## if it times out, just start from the page that you were on (change the page = # in the while loop below)\n",
    "## and continue from there\n",
    "\n",
    "## if you need to pick up where you left off, make sure to put the current files in their own folder\n",
    "## because it will overwrite them if you do not separate them\n",
    "\n",
    "folder_path = '/Users/ashik/UVA/ds 6021 project/arabica_final'  # or arabica\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# open chromedriver\n",
    "driver = webdriver.Chrome()\n",
    "wait = WebDriverWait(driver, 10)\n",
    "time.sleep(2)\n",
    "\n",
    "# navigate to login page\n",
    "driver.get('https://database.coffeeinstitute.org/login')\n",
    "time.sleep(3)\n",
    "\n",
    "# submit login credentials\n",
    "form = wait.until(EC.presence_of_element_located((By.XPATH, '//html/body/content[@class=\"scrollable\"]/div[@class=\"container page\"]/div[@class=\"form short\"]/div[@class=\"login panel\"]/form'))) # NOTE: find_element_by_* has been removed\n",
    "\n",
    "# form = driver.find_element('xpath', '//html/body/content[@class=\"scrollable\"]/div[@class=\"container page\"]/div[@class=\"form short\"]/div[@class=\"login panel\"]/form') # NOTE: find_element_by_* has been removed\n",
    "username = driver.find_element('name', \"username\")\n",
    "password = driver.find_element('name', \"password\")\n",
    "time.sleep(2)\n",
    "\n",
    "username.send_keys(login_email)\n",
    "password.send_keys(login_password)\n",
    "driver.find_element('class name', \"submit\").click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "# navigate to coffees page, then to arabicas page containing links to all quality reports\n",
    "# coffees = driver.find_element('xpath', '//html/body/header/nav[@id=\"main\"]/div[@class=\"container\"]/div[@class=\"in\"]/a[@href=\"/coffees\"]').click()\n",
    "coffees = wait.until(EC.presence_of_element_located((By.XPATH, '//html/body/header/nav[@id=\"main\"]/div[@class=\"container\"]/div[@class=\"in\"]/a[@href=\"/coffees\"]'))).click()#\n",
    "\n",
    "time.sleep(5)\n",
    "driver.find_element('link text', 'Arabica Coffees').click()\n",
    "time.sleep(3)\n",
    "\n",
    "# these values can be changed if this breaks midway through collecting data to pick up close to where you left off\n",
    "page = 6\n",
    "coffeenum = 0\n",
    "\n",
    "\n",
    "\n",
    "while True:\n",
    "\tprint('page {}'.format(page))\n",
    "\n",
    "\t# 50 rows in these tables * 7 columns per row = 350 cells. Every 7th cell clicks through to that coffee's data page\n",
    "\tfor i in range(1, 400, 8):\n",
    "\t\ttime.sleep(2)\n",
    "\n",
    "\t\t# paginate back to the desired page number\n",
    "\t\t# don't think there's a way around this - the back() option goes too far back\n",
    "\t\t# some page numbers aren't available in the ui, but 'next' always is unless you've reached the end\n",
    "\t\tfor p_num in range(page):\n",
    "\t\t\tpage_buttons = driver.find_elements('class name', 'paginate_button')\n",
    "\t\t\tpage_buttons[-1].click() # the 'next' button\n",
    "\t\t\ttime.sleep(1)\n",
    "\t\t\tpage_buttons = driver.find_elements('class name', 'paginate_button')\n",
    "\n",
    "\t\t# select the cell to click through to the next coffee-data page\n",
    "\t\ttime.sleep(2) # this next line errors out sometimes, maybe it needs more of a time buffer\n",
    "\t\ttest_page = driver.find_elements('xpath', '//td')[i].click()\n",
    "\t\ttime.sleep(2)\n",
    "\t\tprint('rows: ')\n",
    "\t\tprint(len(driver.find_elements('xpath', \"//tr\")))\n",
    "\t\ttables = driver.find_elements(By.TAG_NAME, \"table\")\n",
    "\n",
    "\t\t# loop over all coffee reports on the page, processing each one and writing to csv\n",
    "\t\tprint('tables: ')\n",
    "\t\tprint(len(tables))\n",
    "\t\tj = 0\n",
    "\t\tfor tab in tables:\n",
    "\t\t\ttry:\n",
    "\t\t\t\tt = BeautifulSoup(tab.get_attribute('outerHTML'), \"html.parser\")\n",
    "\t\t\t\t#print(t)\n",
    "\t\t\t\tdf = pd.read_html(str(t))\n",
    "\t\t\t\tname = 'coffee_{}_table_{}.csv'.format(coffeenum, j)\n",
    "\t\t\t\tdf[0].to_csv(name)\n",
    "\t\t\t\tprint(name)\n",
    "\t\t\texcept:\n",
    "\t\t\t\t# only one's needed but I want this to be obnoxious since it's the only way I'm logging this currently\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\t\tprint('ERROR: {} failed'.format(name))\n",
    "\t\t\tj += 1\n",
    "\n",
    "\t\t# go back to page with all other coffee results\n",
    "\t\t#driver.back() # note: this isn't working as expected, manually going back to pg 1 via url instead\n",
    "\t\tdriver.get('https://database.coffeeinstitute.org/coffees/arabica')\n",
    "\t\ttime.sleep(2)\n",
    "\t\tcoffeenum += 1\n",
    "\n",
    "\tpage += 1\n",
    "\tif page == 7: # or however many pages there are\n",
    "\t\tbreak\n",
    "\n",
    "\n",
    "# close the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23b980b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Change this to your working directory\n",
    "folder_path = '/Users/ashik/UVA/ds 6021 project/arabica_final/page 7'  # or arabica\n",
    "os.chdir(folder_path)\n",
    "\n",
    "# List all files in directory\n",
    "all_files = os.listdir()\n",
    "\n",
    "# Keep only valid files matching coffee_#_table_#.csv\n",
    "coffee_list = (\n",
    "    pd.DataFrame({'files': all_files})\n",
    "    .query(\"files.str.match(r'^coffee_\\\\d+_table_\\\\d+\\\\.csv$')\", engine='python')\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Check how many valid coffee files were found\n",
    "print(f\"Found {len(coffee_list)} valid coffee files.\")\n",
    "if len(coffee_list) == 0:\n",
    "    raise ValueError(\"No valid coffee_#_table_#.csv files found. Check your folder path.\")\n",
    "\n",
    "# Split filenames to identify coffee IDs and tables\n",
    "coffee_list_split_temp = coffee_list['files'].str.split(pat='_', n=2, expand=True)\n",
    "coffee_list_split_temp.columns = ['coffee', 'id', 'tables']\n",
    "\n",
    "# Combine parts for easier grouping\n",
    "coffee_list_split = pd.DataFrame({\n",
    "    'coffee': coffee_list_split_temp['coffee'] + '_' + coffee_list_split_temp['id'],\n",
    "    'tables': coffee_list_split_temp['tables']\n",
    "})\n",
    "\n",
    "# Count tables per coffee\n",
    "table_counts = coffee_list_split.groupby('coffee').count()\n",
    "print(\"Coffees missing some tables:\")\n",
    "print(table_counts[table_counts['tables'] != 5])\n",
    "\n",
    "# Identify which coffee IDs to skip\n",
    "incomplete = table_counts[table_counts['tables'] != 5].index.tolist()\n",
    "skips = [int(c.split('_')[1]) for c in incomplete]\n",
    "print(\"Skipping:\", skips)\n",
    "\n",
    "df_list = []\n",
    "\n",
    "for i in range(210):\n",
    "    if i in skips:\n",
    "        print(f\"Skipping {i}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        df0 = pd.read_csv(f'coffee_{i}_table_0.csv')\n",
    "        df1 = pd.read_csv(f'coffee_{i}_table_1.csv')\n",
    "        df2 = pd.read_csv(f'coffee_{i}_table_2.csv')\n",
    "        df3 = pd.read_csv(f'coffee_{i}_table_3.csv')\n",
    "        df4 = pd.read_csv(f'coffee_{i}_table_4.csv')\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Missing file(s) for coffee_{i}\")\n",
    "        continue\n",
    "\n",
    "    # Process df1\n",
    "    df1.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df1['one'].tolist()\n",
    "    colnames2 = df1['three'].tolist()\n",
    "    data1 = df1['two'].tolist()\n",
    "    data2 = df1['four'].tolist()\n",
    "    df1_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df2\n",
    "    df2.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df2['one'].tolist()\n",
    "    colnames2 = df2['three'].tolist()\n",
    "    data1 = df2['two'].tolist()\n",
    "    data2 = df2['four'].tolist()\n",
    "    df2_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df3\n",
    "    df3.columns = ['zero', 'one', 'two', 'three', 'four']\n",
    "    colnames1 = df3['one'].tolist()\n",
    "    colnames2 = df3['three'].tolist()\n",
    "    data1 = df3['two'].tolist()\n",
    "    data2 = df3['four'].tolist()\n",
    "    df3_processed = pd.DataFrame([(data1 + data2)], columns=(colnames1 + colnames2))\n",
    "\n",
    "    # Process df4\n",
    "    df4.columns = ['zero', 'one', 'two']\n",
    "    colnames1 = df4['one'].tolist()\n",
    "    data1 = df4['two'].tolist()\n",
    "    df4_processed = pd.DataFrame([data1], columns=colnames1)\n",
    "\n",
    "    if i > 1:\n",
    "        prev_cols = df.columns\n",
    "\n",
    "    df = pd.concat([df1_processed, df2_processed, df3_processed, df4_processed], axis=1)\n",
    "    df = df.rename(columns={np.nan: \"NA\"})\n",
    "    df_list.append(df)\n",
    "    print(i)\n",
    "\n",
    "    these_cols = df.columns\n",
    "    if i > 1:\n",
    "        pass\n",
    "\n",
    "j = 0\n",
    "for i in df_list:\n",
    "    print(f\"{j} shape: {i.shape}\")\n",
    "    j += 1\n",
    "\n",
    "df_final = pd.concat(df_list, axis=0)\n",
    "print(df_final.columns)\n",
    "print(df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "df_final.to_csv('df_7_arabica.csv', index=False)\n",
    "\n",
    "# figure out what coffee_89 is and manually had to add it back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ff60bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/Users/ashik/UVA/ds 6021 project/arabica_final'  # or arabica\n",
    "os.chdir(folder_path)\n",
    "\n",
    "one = pd.read_csv('df_1to3_arabica.csv')\n",
    "two = pd.read_csv('df_4_arabica.csv')\n",
    "three = pd.read_csv('df_5-6_arabica.csv')\n",
    "four = pd.read_csv('df_7_arabica.csv')\n",
    "\n",
    "df_final = pd.concat([one, two, three, four], axis=0)\n",
    "print(df_final.columns)\n",
    "print(df_final.shape)\n",
    "print(df_final.head())\n",
    "\n",
    "df_final.to_csv('df_arabica.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
